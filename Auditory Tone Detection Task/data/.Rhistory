rm(list = ls()) #Clear everything in environment
#Notes -----------------------------------------------------------
#Split up the analysis and visualization chunks for ease
#Notes: I currently do not have a cfs to csv/txt conversion script that stores frame-state
# I used section 3 to identify  trial types based on the stimulus artefacts within the sweeps
# I am aware of the limitations of doing this (stimulus artefacts are not digitally included)
# While it is possible to determine the ISI between stimulus artefacts to determine trial types
# e.g., an ISI of 2-5 ms could be SICI (which can be determined by comparing peak latencies)
# The stimulus artefacts are not always going to be perfectly sampled (depends on sampling-rate)
# There will also be instances where background EMG will drown out the signal from the stimulus artefacts
# I leave trial type identification here with the hope that it will be optimised in the future
# but users should always refer to the frame state to determine trial type if they want to be perfectly accurate
# Notes  ------------------------------------------------------------------
#This script was created to analyze data for a specific TMS project, but I am finding a way to make it adaptable to most users
#There are a lot of similarities between projects, so I would hope this solution should work for most people
# Packages -------------------------------------------------------
load.packages <- function(pkg) {
new.pkg <- pkg[!(pkg %in% installed.packages()[ , "Package"])]
if (length(new.pkg)) {
install.packages(new.pkg, dependencies = T)
}
sapply(pkg, require, character.only = T)
}
packages <- c("tidyverse", "nlme", "ggpubr", "Hmisc", "plyr", "Rmisc", "retimes", "data.table", "lme4","multcomp",
"pastecs", "effects", "DataCombine", "gridExtra", "leaps", "ppcor", "ggm", "readxl", "emmeans",
"eeptools", "psych","weights", "here", "cowplot", "corrplot", "changepoint", "changepoint.np")
load.packages(packages)
print('hello')
rm(list = ls()) #Clear everything in environment
#Notes -----------------------------------------------------------
#Split up the analysis and visualization chunks for ease
#Notes: I currently do not have a cfs to csv/txt conversion script that stores frame-state
# I used section 3 to identify  trial types based on the stimulus artefacts within the sweeps
# I am aware of the limitations of doing this (stimulus artefacts are not digitally included)
# While it is possible to determine the ISI between stimulus artefacts to determine trial types
# e.g., an ISI of 2-5 ms could be SICI (which can be determined by comparing peak latencies)
# The stimulus artefacts are not always going to be perfectly sampled (depends on sampling-rate)
# There will also be instances where background EMG will drown out the signal from the stimulus artefacts
# I leave trial type identification here with the hope that it will be optimised in the future
# but users should always refer to the frame state to determine trial type if they want to be perfectly accurate
# Notes  ------------------------------------------------------------------
#This script was created to analyze data for a specific TMS project, but I am finding a way to make it adaptable to most users
#There are a lot of similarities between projects, so I would hope this solution should work for most people
# Packages -------------------------------------------------------
load.packages <- function(pkg) {
new.pkg <- pkg[!(pkg %in% installed.packages()[ , "Package"])]
if (length(new.pkg)) {
install.packages(new.pkg, dependencies = T)
}
sapply(pkg, require, character.only = T)
}
packages <- c("tidyverse", "nlme", "ggpubr", "Hmisc", "plyr", "Rmisc", "retimes", "data.table", "lme4","multcomp",
"pastecs", "effects", "DataCombine", "gridExtra", "leaps", "ppcor", "ggm", "readxl", "emmeans",
"eeptools", "psych","weights", "here", "cowplot", "corrplot", "changepoint", "changepoint.np")
load.packages(packages)
# Functions -------------------------------------------------------
theme_color <- c("#edae49","#d1495b")
`%notin%` <- Negate(`%in%`)
mepTheme <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
plot.title = element_text(lineheight=.8, size = 10, face = "italic"),
plot.subtitle = element_text(lineheight=.8, size = 10))
RMS <- function(num) sqrt(sum(num^2)/length(num))
rm(list = ls()) #Clear everything in environment
#Notes -----------------------------------------------------------
#Split up the analysis and visualization chunks for ease
#Notes: I currently do not have a cfs to csv/txt conversion script that stores frame-state
# I used section 3 to identify  trial types based on the stimulus artefacts within the sweeps
# I am aware of the limitations of doing this (stimulus artefacts are not digitally included)
# While it is possible to determine the ISI between stimulus artefacts to determine trial types
# e.g., an ISI of 2-5 ms could be SICI (which can be determined by comparing peak latencies)
# The stimulus artefacts are not always going to be perfectly sampled (depends on sampling-rate)
# There will also be instances where background EMG will drown out the signal from the stimulus artefacts
# I leave trial type identification here with the hope that it will be optimised in the future
# but users should always refer to the frame state to determine trial type if they want to be perfectly accurate
# Notes  ------------------------------------------------------------------
#This script was created to analyze data for a specific TMS project, but I am finding a way to make it adaptable to most users
#There are a lot of similarities between projects, so I would hope this solution should work for most people
# Packages -------------------------------------------------------
load.packages <- function(pkg) {
new.pkg <- pkg[!(pkg %in% installed.packages()[ , "Package"])]
if (length(new.pkg)) {
install.packages(new.pkg, dependencies = T)
}
sapply(pkg, require, character.only = T)
}
packages <- c("tidyverse", "nlme", "ggpubr", "Hmisc", "plyr", "Rmisc", "retimes", "data.table", "lme4","multcomp",
"pastecs", "effects", "DataCombine", "gridExtra", "leaps", "ppcor", "ggm", "readxl", "emmeans",
"eeptools", "psych","weights", "here", "cowplot", "corrplot", "changepoint", "changepoint.np")
load.packages(packages)
# Functions -------------------------------------------------------
theme_color <- c("#edae49","#d1495b")
`%notin%` <- Negate(`%in%`)
mepTheme <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
plot.title = element_text(lineheight=.8, size = 10, face = "italic"),
plot.subtitle = element_text(lineheight=.8, size = 10))
RMS <- function(num) sqrt(sum(num^2)/length(num))
peak2peak <-  function(x){
localMaximum <- as.data.frame(lapply(x, max))
localMinimum <- as.data.frame(lapply(x, min))
peak_to_peak_mV <- t(abs(abs(localMaximum) + abs(localMinimum)))
return(peak_to_peak_mV)
}
ICF_detection <- function(x){
trial <- as.data.frame(x)
temp <- (c(trial[18,], trial[19,], trial[20,], trial[21,], trial[22,])) #these are the trial numbers around where the first stimulus artefact would be
minimum_within_timeframe <- min(temp)
true_or_false_ICF <- ifelse(minimum_within_timeframe <= -0.055, "ICF", NA)
return(true_or_false_ICF)
}
SICI_detection <- function(x){
trial <- as.data.frame(x)
temp <- (c(trial[32,], trial[33,], trial[34,], trial[35,], trial[36,])) #these are the trial numbers around where the first stimulus artefact would be
minimum_within_timeframe <- min(temp)
true_or_false_SICI <- ifelse(minimum_within_timeframe <= -0.055, "SICI", NA)
return(true_or_false_SICI)
}
LICI_detection <- function(x){
trial <- x
firstTenSamples <- trial[1:10]
largest_value_in_firstTenSamples <- max(abs(firstTenSamples))
true_or_false_LICI <-  ifelse(largest_value_in_firstTenSamples > 0.5, "LICI", "NA")
return(true_or_false_LICI)
}
CSP_detection <- function(x){
trial <- as.data.frame(x)
RMS_across_trial_duration <- RMS(trial)
true_or_false_CSP <- ifelse(RMS_across_trial_duration >= 5, "CSP or noise", NA)
return(true_or_false_CSP)
}
filename_extraction_JHU <- function(x){
#Assign filename
filename <- x
#get some landmarks within the filename string
firstHardBracketStart <- str_locate(filename, pattern = c("\\[1"))[1] #location of the first hard bracket start
firstHardBracketEnd <- str_locate(filename, pattern = c("\\]"))[1] #location of the first hard bracket end
start_of_extension <- str_locate(filename, pattern = ".txt")[1]
#Basic details
filename_split <- str_split(filename, "_", simplify = TRUE) #split the string based on underscores
participant_number <- filename_split[1] #subject number
date <- filename_split[2] #date of testing
#TMS specific details
trial_type <- filename_split[3] #trial type
target_hemisphere <- gsub( "m1","", filename_split[4]) #hemisphere
target_hand <- ifelse(target_hemisphere=="l", "R", "L")
#number of trials
range_of_trials <- substr(filename, firstHardBracketStart, firstHardBracketEnd) #identifies the range of trials [1-*]
number_of_trials <- as.numeric(gsub("\\[1-|\\]", "", range_of_trials)) #get value for number of trials (remove irrelevant values in the range)
#number of channels
channel_range <- str_sub(filename, firstHardBracketEnd + 1, start_of_extension - 1)
channel_names <- str_split(gsub("|\\[|\\]", "", channel_range), ",", simplify = TRUE)
channel_names <- gsub("  ", "", channel_names)
channel_names <- gsub(" ", "_", channel_names)
number_of_channels <- length(channel_names)
#Maximum stimulator output
MSO <- substr(filename, str_locate(filename, "at"), firstHardBracketStart - 1)
MSO <- gsub("at", "", MSO)
MSO <- str_split(MSO, "_",)
MSO <- unlist(MSO)
MSO <- MSO[!MSO==""]
if(length(MSO) == 2){
MSO_top <- MSO[1]
MSO_bottom <- MSO[2]
} else {
MSO_top <- NA
MSO_bottom <- NA
}
#original filename
original_filename <- substr(x,1,firstHardBracketStart-1)
#save information about the participant based on the filename
participant_information <- cbind(participant_number, number_of_trials, number_of_channels, channel_names, target_hand, MSO_top, MSO_bottom, original_filename)
return(participant_information)
}
# Setup ----------------------------------------------------------------
baseDirectory <- here("data", "tms_data") #set your base directory using the here function
filenames <- list.files(here("data", "tms-data","Converted CFS 2 Text Files - KKI"), pattern = "lici") #list the .txt files in your directory
plotting_toggle <- "on" #assign "on" to for plotting, else "off"
print(paste("Plotting:", plotting_toggle))
current_files <- filenames #specify the files you currently wish to process
for(f in 1:length(current_files)){
# 0. Read in the data -----------------------------------------------------
tms_data <- read.csv(here("data", "tms-data","Converted CFS 2 Text Files - KKI", current_files[f]), sep = "\t", header = FALSE)
tms_data <- cbind(1:nrow(tms_data), tms_data) #add row number as a column
names(tms_data)[1] <- "rowNumber" #name the row number column rowNumber
names(tms_data)[names(tms_data) == 'V1'] <- c("time") #label the first column as time
tms_data$time <- as.numeric(substr(as.character(tms_data$time), 1,6)) * 1000 #reduce the time column (dependent on sampling rate) & convert to ms (*1000)
# 1. Extract participant and sessions details  ------------------------------
participant_details <- as.data.frame(filename_extraction_JHU(current_files[f]))
#Specify key information required for subsequent sections
participant_number <- participant_details$participant_number
number_of_channels <- as.numeric(as.character(participant_details$number_of_channels)) #specify number of channels (manually or based on participant_details)
number_of_trials <- (ncol(tms_data)- 2)/(number_of_channels)#number of trials = ncol - 2, since ncol[1] = sampling points
channel_names <- participant_details[grep("V",colnames(participant_details))] #the channel names will have been given default colnames with "V"
MSO_top <- participant_details$MSO_top
MSO_bottom <- participant_details$MSO_bottom
target_hand <- participant_details$target_hand
original_filename <- as.character(participant_details$original_filename)
#Print out information about this partcipant if debugging is "on" - WIP
print(paste("Now analysing and plotting TMS data from the file:", participant_details$original_filename))
print(paste("This participant file has", participant_details$number_of_channels, "channel(s) and", participant_details$number_of_trials, "trial(s) per channel"))
# 2. Apply change point analysis to detect stimulus artefacts --------------
# identify the change points
common_change_points <- list() #First, create a list of the change points
for(s in 3:ncol(tms_data)){
sweep <- tms_data[[s]] #subset to current sweep
#sweep <- sweep[1:400]
sweep_amoc = cpt.var(sweep, method = "PELT", penalty = "Manual", pen.value = "2*log(n)")
param.est(sweep_amoc) #unsure what this does
#save the change points in the list
common_change_points[[s]] <-  cpts(sweep_amoc)
}
#Identify the change points that are very likely to be the stimulus artefact(s)
# this is done through finding the most common change point in the sweep, which will very likely be the stimulus artefact
# in cases where it is not the stimulus artefact, you will need to narrow the window to where the stimulus artefact is likely to be
# an example of this is done for identifying where the conditioning stimulus artefact is (within the first 30 sampling points)
all_change_points <- unlist(common_change_points) #unlist all the change points
frequency_of_change_points <- sort(table(all_change_points), decreasing = TRUE) #sort by most frequent
stimulus_artefact <- names(frequency_of_change_points[1]) #the most frequent change point is the stimulus artefact (appears in every trial)
#Identify the change points that are likel to be the conditioning stimulus artefact(s) in a paired-pulse trial with long ISIs
frequency_of_change_points_in_conditioning_window <- sort(table(all_change_points[all_change_points<200]),decreasing = TRUE)
#find the corresponding value for each change point
values_for_change_points <- list()
for(n in names(frequency_of_change_points_in_conditioning_window)){
values_for_change_points[[n]] <- sweep[as.numeric(n)]
}
values_for_change_points <- unlist(values_for_change_points)
#identify the change point in the conditioning stimulus window that is smaller (it usually is the end of the stimulus artefact rather than the start - which is what we want)
frequency_of_change_points_in_conditioning_window_with_values <- t(rbind(frequency_of_change_points_in_conditioning_window, values_for_change_points))
selected_change_point <- ifelse(abs(frequency_of_change_points_in_conditioning_window_with_values[2]) > abs(frequency_of_change_points_in_conditioning_window_with_values[3]), 3, 2)
conditioning_stimulus_artefact <- names(sort(table(all_change_points[all_change_points<200]),decreasing = TRUE)[selected_change_point])
#If there is no conditioning stimulus, make conditioning_stimulus_artefact = NA
if(length(frequency_of_change_points_in_conditioning_window)==0){
conditioning_stimulus_artefact <- NA
}
# 3. Analyze each trial  --------------------------------
tms_data_without_row_and_time <- tms_data[3:ncol(tms_data)] #remove the first two columns (row number and time)
colnames(tms_data_without_row_and_time) <- rep(1:number_of_trials, number_of_channels) #rename the column names to be sweep number starting from 1
#Split data by channel and store them in a list "tms_data_by_channel"
tms_data_by_channel <- list() #create a list
starting_value <- 1
ending_value <- as.numeric(as.character(number_of_trials))
for(c in 1:number_of_channels){
tms_data_by_channel[[c]] <- tms_data_without_row_and_time[starting_value:ending_value]
starting_value <- starting_value + number_of_trials
ending_value <- ending_value + number_of_trials
}
sweep_data_by_channel <- list()
for(current_channel in 1:number_of_channels){
list_of_outcomes_by_sweep <- list() #Create an external list for outcome data extracted from each sweep
for(s in 1:number_of_trials){
tms_data_for_current_channel <- cbind(tms_data[1:2], tms_data_by_channel[current_channel]) #reappend the row number and time columns
sweep <- tms_data_for_current_channel[[s + 2]] #set sweep to be the sweep data from the current channel (s + 2 because we want to skip the first two columns)
sweep_amoc = cpt.var(sweep, method = "PELT", penalty = "Manual", pen.value = "2*log(n)")
change_point_locations <- cpts(sweep_amoc)
#plot(sweep_amoc, ylim = c(-1,1)) #leave this line for debugging purposes
# Create landmarks for where the stimulus artefact begin and end
window_before_conditioning_stimulus_artefact <- as.numeric(conditioning_stimulus_artefact) - 10
window_after_conditioning_stimulus_artefact <- as.numeric(conditioning_stimulus_artefact) + 10
window_before_artefact <- as.numeric(stimulus_artefact)-20 #nb. the window is wider to account for the short ISI conditioning pulse
window_after_artefact <- as.numeric(stimulus_artefact)+20 #see above comment
end_of_mep <- window_after_artefact + 100
end_of_conditioning_mep <- window_after_conditioning_stimulus_artefact + 100
test_pulse_mep_window <- sweep[window_after_artefact:end_of_mep]
conditioning_pulse_mep_window <- ifelse(is.na(end_of_conditioning_mep), NA, list(sweep[window_after_conditioning_stimulus_artefact:end_of_conditioning_mep]))
# Determine trial to be either single or paired-pulse with long ISI
number_of_early_change_points <- length(change_point_locations[change_point_locations <= as.numeric(conditioning_stimulus_artefact) + 30]) #NOTE THIS IS TEMP - 30 is a likely place for where the conditioning pulse will be
trial_type <- "Single" #By default, assume trial_type is a single pulse trial
trial_type <- ifelse(trial_type == "Single" & number_of_early_change_points <= 3 & number_of_early_change_points > 1, "Paired - long ISI", trial_type) #assign trial type to be paired if there's an early stimulus artefact
trial_type <- ifelse(RMS(sweep) > 1.0, "Silent Period",trial_type)
trial_type <- ifelse(RMS(sweep[window_before_artefact:window_after_artefact]) < 0.01, NA, trial_type)
trial <- s #trial number
# Extract peak to peak and RMS for the MEP induced by the test pulse and *if present* conditioning pulse
test_pulse_peak_to_peak <- abs(max(test_pulse_mep_window)) + abs(min(test_pulse_mep_window))
RMS_before_stimulus_artefact <- RMS(sweep[(window_before_artefact-50):window_before_artefact]) #was - 100?
conditioning_pulse_peak_to_peak <- ifelse(is.na(end_of_conditioning_mep), NA, abs(max(unlist(conditioning_pulse_mep_window))) + abs(min(unlist(conditioning_pulse_mep_window))))
#Combine extracted data for the current sweep
channel_name <- as.character(channel_names[[current_channel]]) #Create channel name variable
participant_information_and_outcomes_for_s_sweep <- cbind(participant_number, trial_type,
target_hand, RMS_before_stimulus_artefact,
test_pulse_peak_to_peak, conditioning_pulse_peak_to_peak,
channel_name, number_of_trials, number_of_channels,
MSO_top, MSO_bottom, original_filename)
list_of_outcomes_by_sweep[[s]] <- as.data.frame(participant_information_and_outcomes_for_s_sweep) #Store the sweep outcomes
} #end of sweep extraction
sweep_data_by_channel[[current_channel]] <- do.call(rbind, list_of_outcomes_by_sweep)
} #end of sweep extraction by channels
#Store the analyzed data
names(sweep_data_by_channel) <- as.matrix(channel_names) #name the sweep_data_by_channel using the channel names
all_tms_data <- as.data.frame(bind_rows(sweep_data_by_channel))
all_tms_data$participant_number <- as.character(all_tms_data$participant_number)
all_tms_data$target_hand <- as.character(all_tms_data$target_hand)
write_csv(all_tms_data, path = here("data", "tms-data", "processed", "individual-data", gsub(".txt", ".csv", current_files[f])))
# 4. visualize the data in the sweep ---------------------------------------
if(plotting_toggle == "on"){ #Conditional plotting based on whether plotting toggle is "on"
list_of_plots_by_channel <- list() #Create an extrnal list for the plots of each channel to reside in
for(current_channel in 1:number_of_channels){
#set tms_data for current channel - reappend the row number and time columns
tms_data_for_current_channel <- cbind(tms_data[1:2], tms_data_by_channel[current_channel])
# Create landmarks for where the stimulus artefact begin and end
window_before_conditioning_stimulus_artefact <- as.numeric(conditioning_stimulus_artefact) - 10
window_after_conditioning_stimulus_artefact <- as.numeric(conditioning_stimulus_artefact) + 10
window_before_artefact <- as.numeric(stimulus_artefact)-20 #nb. the window is wider to account for the short ISI conditioning pulse
window_after_artefact <- as.numeric(stimulus_artefact)+20 #see above comment
end_of_mep <- window_after_artefact + 100
end_of_conditioning_mep <- window_after_conditioning_stimulus_artefact + 100
test_pulse_mep_window <- sweep[window_after_artefact:end_of_mep]
conditioning_pulse_mep_window <- ifelse(is.na(end_of_conditioning_mep), NA, list(sweep[window_after_conditioning_stimulus_artefact:end_of_conditioning_mep]))
list_of_sweep_plots <- list()
for(s in 1:number_of_trials){
trial_type <- sweep_data_by_channel[[current_channel]]$trial_type[s]
RMS_before_stimulus_artefact <- as.numeric(as.character(sweep_data_by_channel[[current_channel]]$RMS_before_stimulus_artefact[s]))
test_pulse_peak_to_peak <- as.numeric(as.character(sweep_data_by_channel[[current_channel]]$test_pulse_peak_to_peak[s]))
conditioning_pulse_peak_to_peak <- as.numeric(as.character(sweep_data_by_channel[[current_channel]]$conditioning_pulse_peak_to_peak[s]))
# Base plot
plot <- ggplot(data= tms_data_for_current_channel, aes(x=rowNumber)) +
aes_string(y = tms_data_for_current_channel[[s + 2]]) +
geom_line(size = 0.3) + ylim(-1, 1) + xlim(0,600) +
annotate("rect", xmin = as.numeric(window_before_artefact), xmax = as.numeric(window_after_artefact), ymin = -1, ymax = 1, alpha = .4, fill = "black") +
geom_vline(xintercept=as.numeric(stimulus_artefact), color = "black") +
geom_vline(xintercept=as.numeric(window_after_artefact), color = "black", linetype="dashed") +
geom_vline(xintercept=as.numeric(end_of_mep), color = "black", linetype="dashed") +
labs(y = "mV", x = "Sampling points", tag = s, title = paste("Type:", "Standard",
"\nRMS:", round(RMS_before_stimulus_artefact, digits = 3), "(mV)",
"; Test pulse:", round(test_pulse_peak_to_peak, digits = 3), "(mV)")) +
mepTheme
# Plots for paired-pulse trial with long ISIs
if(trial_type %in% c("Paired - long ISI")){
plot <- plot + annotate("rect", xmin = as.numeric(window_before_conditioning_stimulus_artefact), xmax = as.numeric(window_after_conditioning_stimulus_artefact), ymin = -1, ymax = 1, alpha = .4, fill = "black") +
geom_vline(xintercept=as.numeric(conditioning_stimulus_artefact), color = "black") +
geom_vline(xintercept=as.numeric(window_after_conditioning_stimulus_artefact), color = "black", linetype="dashed") +
geom_vline(xintercept=as.numeric(end_of_conditioning_mep), color = "black", linetype="dashed") +
labs(y = "mV", x = "Sampling points", tag = s, title = paste("Type:", "Long ISI paired-pulse",
"\nConditioning pulse:", round(conditioning_pulse_peak_to_peak, digits =3), "(mV)",
"; Test pulse:", round(test_pulse_peak_to_peak, digits =3), "(mV)"))
}
# Silent period
if(trial_type %in% c("Silent Period")){
plot <- plot +
labs(y = "mV", x = "Sampling points", tag = s, title = paste("Type:", "Silent period"),
"\nSilent Period Duration (ms):", NA, "(mV)")
}
# Silent period
if(is.na(trial_type)){
plot <- ggplot(data= tms_data_for_current_channel, aes(x=rowNumber)) +
aes_string(y = tms_data_for_current_channel[[s + 2]]) +
geom_line(size = 0.3) + ylim(-1, 1) + xlim(0,400) +
labs(y = "mV", x = "Sampling points", tag = s, title = paste("Type:", "NA")) +
mepTheme
}
list_of_sweep_plots[[s]] <- plot #Store the plots
} #end of plots by sweep
#Arrange and label the plots
list_of_sweep_plots_by_page <- split(list_of_sweep_plots, ceiling(seq_along(list_of_sweep_plots)/30)) #split into lists of 30
all_sweep_plots <- list()
for(page in 1:length(list_of_sweep_plots_by_page)){
all_sweep_plots_unlabelled <- ggarrange(plotlist = list_of_sweep_plots_by_page[[page]], widths = c(1,1), ncol = 5, nrow = 6, align = "hv")
all_sweep_plots_with_channel <- ggpubr::annotate_figure(all_sweep_plots_unlabelled, top = ggpubr::text_grob(paste("channel: ", as.matrix(channel_names)[current_channel]), color = "black", size = 15))
all_sweep_plots_with_channel_and_filename <- ggpubr::annotate_figure(all_sweep_plots_with_channel, top = ggpubr::text_grob(paste0("Original filename: ", original_filename), color = "black", face = "italic", size = 15))
all_sweep_plots_with_channel_and_filename_and_header <- ggpubr::annotate_figure(all_sweep_plots_with_channel_and_filename, top = ggpubr::text_grob("GABA TS Study", color = "black", face = "bold", size = 20))
all_sweep_plots[[page]] <- all_sweep_plots_with_channel_and_filename_and_header
} #end of arranging and labelling plots
list_of_plots_by_channel[[current_channel]] <- all_sweep_plots
} #end of plots by channels
print("Now saving plots")
setwd("/Users/jasonhe/Documents/Documents - Jason's iCloud/Work/OneDrive - King's College London/Projects/JHU/GABA-TS/scripts/MRS-TMS-TAC_in_TS/Neurobiological predictors of Premonitory Urges in TS/data/tms-data/processed/plots")
pdfFileName <-  gsub(".txt", ".pdf", current_files[f])
pdf(pdfFileName, onefile = TRUE, width = 20, height = 12)
print(list_of_plots_by_channel)
dev.off()
} #end of optional plot toggle
} #end of current_file list
# # Saving combined dataframes  -------------------------------------------------------------
# #Combine the processed data for each participant and save them in a 'combined folder in both wide and long format
# setwd("~/Documents/Documents - Jason's iCloud/Work/OneDrive - King's College London/Projects/JHU/GABA-TS/scripts/MRS-TMS-TAC_in_TS/Neurobiological predictors of Premonitory Urges in TS/data/tms-data/processed/individual-data")
# filenames <- list.files(here("data", "tms-data","processed", "individual-data"), pattern = ".csv") #List files in the CCH directory
#
# concatenated_tms_data <- list.files(path=here("data", "tms-data","processed", "individual-data"), full.names = TRUE) %>%
#   lapply(read.csv, header = TRUE, colClasses = "character") %>%
#   bind_rows
#
# #Save a long format
# concatenated_tms_data_long <- concatenated_tms_data
# concatenated_tms_data_long$participant_number <- as.numeric(concatenated_tms_data_long$participant_number)
# write_csv(concatenated_tms_data_long, here("data", "tms-data","processed", "combined-data", "concatenated_tms_data_long.csv")) #write csv
#
# #reshape the data from long to wide format (without using reshape (problem prone))
#
# #Specify the dataframe that you wish to go from long to wide
# data <- concatenated_tms_data_long
#
# #Specify columns of the long format that will stay the way they are
# constant_columns <- c("participant_number", "trial", "trial_type", "target_hand",
#                       "number_of_trials", "number_of_channels",
#                       "MSO_top", "MSO_bottom",
#                       "original_filename")
#
# #Specify the key variable that we want to become 'wide'
# key_variable <- c("channel")
#
# #Specify the column name of the participant id
# id <- c("original_filename")
#
# unique_factors_of_key_variable <- unique(data[[key_variable]]) #identify the unique factor levels of the key variable
#
# list_for_wide_data_for_each_unique_id <- list()
# unique_id <- unique(data[[id]]) #identify the unqique filenames for the id variable
# for(u in 1:length(unique_id)){
#   current_file <- data[data$original_filename==unique_id[u],] #set the current file to the u in unique filenames
#   long_columns <- current_file[colnames(current_file) %in% constant_columns]
#   wide_columns <- current_file[!colnames(current_file) %in% constant_columns]
#
#   list_of_dataframes_split_by_factor <- list()
#   for(f in unique_factors_of_key_variable){
#     dataframe_for_current_unique_factor <- wide_columns[wide_columns[key_variable]==f,]
#     colnames(dataframe_for_current_unique_factor) <- paste0(colnames(dataframe_for_current_unique_factor), "_",f) #append the key_variable factor to colname
#     dataframe_for_current_unique_factor <- dataframe_for_current_unique_factor[!grepl(key_variable, colnames(dataframe_for_current_unique_factor))] #remove key variable as a column
#     list_of_dataframes_split_by_factor[[f]] <- as.data.frame(dataframe_for_current_unique_factor)
#   }
#
#   largest_number_of_rows <- max(sapply(list_of_dataframes_split_by_factor, nrow))
#
#   list_of_row_appended_dataframes <- list()
#   for(d in 1:length(list_of_dataframes_split_by_factor)){
#     dataframe <- list_of_dataframes_split_by_factor[[d]]
#     nrows_to_append <- abs(nrow(dataframe) - largest_number_of_rows) #calculate the number of rows to add
#     if(nrows_to_append > 0){
#       dataframe[nrow(dataframe) + nrows_to_append,] <- NA #add additional rows
#     } else {
#       dataframe <- dataframe
#     }
#     list_of_row_appended_dataframes[[d]] <- dataframe
#   }
#
#   wide_data <- bind_cols(long_columns[1:largest_number_of_rows[1],], #reappend the long columns
#                          list_of_row_appended_dataframes) #to the now wide columns
#
#   list_for_wide_data_for_each_unique_id[[u]] <- wide_data
# }
#
# concatenated_tms_data_wide <- as.data.frame(bind_rows(list_for_wide_data_for_each_unique_id))
#
# #cleaning of column names
# names(concatenated_tms_data_wide) <- gsub("\\.", "_", colnames(concatenated_tms_data_wide)) #remove full stops and replace with underscores
# names(concatenated_tms_data_wide) <- gsub("EMG1", "EMG_1", colnames(concatenated_tms_data_wide)) #make EMG1 EMG_1
# write_csv(concatenated_tms_data_wide, here("data", "tms-data","processed", "combined-data", "concatenated_tms_data_wide.csv")) #write csv
#
setwd("~/GitHub/Open-source-Auditory-Tone-Detection-Task/Auditory Tone Detection Task/data")
setwd("~/GitHub/Open-source-Auditory-Tone-Detection-Task/Auditory Tone Detection Task/data")
list.files()
list.files()[1]
files <- list.files()[1]
files[1]
participant <- files[1]
read_csv(participant, header = TRUE)
?read_csv
read.csv(participant, header = TRUE)
data <- read.csv(participant, header = TRUE)
